{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e751c5e",
   "metadata": {},
   "source": [
    "### DistillBERT-uncased\n",
    "Playing around with the DistillBERT model to identify and access how it understands language. Model implemented from the transformers library from huggingface. \n",
    "\n",
    "> REF https://medium.com/@skillcate/bert-for-dummies-state-of-the-art-model-from-google-42639953e769\n",
    "\n",
    "> REF https://huggingface.co/inference-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d16441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (4.31.0.dev0)\n",
      "Requirement already satisfied: filelock in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luoco\\miniconda3\\envs\\fntp\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743b4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dcf865cb984583a5bec46d3ec795b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoco\\Miniconda3\\envs\\fntp\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\luoco\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "#'bert-base-uncased' is the model which is used at the bottom of huggingface page.\n",
    "#It's pretrained and you can use it directly on the website.\n",
    "#It is a simple way to understand how the model is functioning using their API inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79f932",
   "metadata": {},
   "source": [
    "### Querying the BERTbase Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d83b1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3799113631248474,\n",
       "  'token': 2689,\n",
       "  'token_str': 'change',\n",
       "  'sequence': 'artificial intelligence will change the world'},\n",
       " {'score': 0.07056517899036407,\n",
       "  'token': 3627,\n",
       "  'token_str': 'rule',\n",
       "  'sequence': 'artificial intelligence will rule the world'},\n",
       " {'score': 0.06935320794582367,\n",
       "  'token': 3828,\n",
       "  'token_str': 'save',\n",
       "  'sequence': 'artificial intelligence will save the world'},\n",
       " {'score': 0.05582581087946892,\n",
       "  'token': 5335,\n",
       "  'token_str': 'improve',\n",
       "  'sequence': 'artificial intelligence will improve the world'},\n",
       " {'score': 0.053564876317977905,\n",
       "  'token': 2491,\n",
       "  'token_str': 'control',\n",
       "  'sequence': 'artificial intelligence will control the world'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Artificial intelligence will [MASK] the world\")\n",
    "#luckily control in further down in the line up of outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a361783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.28483712673187256,\n",
       "  'token': 3008,\n",
       "  'token_str': 'parents',\n",
       "  'sequence': 'what will my parents say when i come home'},\n",
       " {'score': 0.18529456853866577,\n",
       "  'token': 2388,\n",
       "  'token_str': 'mother',\n",
       "  'sequence': 'what will my mother say when i come home'},\n",
       " {'score': 0.13850446045398712,\n",
       "  'token': 3566,\n",
       "  'token_str': 'mom',\n",
       "  'sequence': 'what will my mom say when i come home'},\n",
       " {'score': 0.1018538624048233,\n",
       "  'token': 2269,\n",
       "  'token_str': 'father',\n",
       "  'sequence': 'what will my father say when i come home'},\n",
       " {'score': 0.09254806488752365,\n",
       "  'token': 12954,\n",
       "  'token_str': 'mum',\n",
       "  'sequence': 'what will my mum say when i come home'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"What will my [MASK] say when I come home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6204b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7973992824554443,\n",
       "  'token': 1996,\n",
       "  'token_str': 'the',\n",
       "  'sequence': 'david drove the car to the shops'},\n",
       " {'score': 0.19058717787265778,\n",
       "  'token': 2010,\n",
       "  'token_str': 'his',\n",
       "  'sequence': 'david drove his car to the shops'},\n",
       " {'score': 0.0048079947009682655,\n",
       "  'token': 2014,\n",
       "  'token_str': 'her',\n",
       "  'sequence': 'david drove her car to the shops'},\n",
       " {'score': 0.002805917989462614,\n",
       "  'token': 2037,\n",
       "  'token_str': 'their',\n",
       "  'sequence': 'david drove their car to the shops'},\n",
       " {'score': 0.0015117460861802101,\n",
       "  'token': 1037,\n",
       "  'token_str': 'a',\n",
       "  'sequence': 'david drove a car to the shops'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"David drove [MASK] car to the shops\")\n",
    "#interesting how 'her' is third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a676d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9747549891471863,\n",
       "  'token': 2051,\n",
       "  'token_str': 'time',\n",
       "  'sequence': 'will bought her some time to apologize'},\n",
       " {'score': 0.004497519228607416,\n",
       "  'token': 2686,\n",
       "  'token_str': 'space',\n",
       "  'sequence': 'will bought her some space to apologize'},\n",
       " {'score': 0.0018994241254404187,\n",
       "  'token': 2769,\n",
       "  'token_str': 'money',\n",
       "  'sequence': 'will bought her some money to apologize'},\n",
       " {'score': 0.0010028304532170296,\n",
       "  'token': 4157,\n",
       "  'token_str': 'coffee',\n",
       "  'sequence': 'will bought her some coffee to apologize'},\n",
       " {'score': 0.000876168196555227,\n",
       "  'token': 3823,\n",
       "  'token_str': 'seconds',\n",
       "  'sequence': 'will bought her some seconds to apologize'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Will bought her some [MASK] to apologize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556a0df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.42733877897262573,\n",
       "  'token': 2018,\n",
       "  'token_str': 'had',\n",
       "  'sequence': \"my father's best friend had said she was in a hurry to see us\"},\n",
       " {'score': 0.06766164302825928,\n",
       "  'token': 2467,\n",
       "  'token_str': 'always',\n",
       "  'sequence': \"my father's best friend always said she was in a hurry to see us\"},\n",
       " {'score': 0.021212704479694366,\n",
       "  'token': 2038,\n",
       "  'token_str': 'has',\n",
       "  'sequence': \"my father's best friend has said she was in a hurry to see us\"},\n",
       " {'score': 0.013498571701347828,\n",
       "  'token': 1010,\n",
       "  'token_str': ',',\n",
       "  'sequence': \"my father's best friend, said she was in a hurry to see us\"},\n",
       " {'score': 0.013056142255663872,\n",
       "  'token': 2130,\n",
       "  'token_str': 'even',\n",
       "  'sequence': \"my father's best friend even said she was in a hurry to see us\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"My father's best friend [MASK] said she was in a hurry to see us\")\n",
    "#I was hoping the model would give us a name but it didn't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be48ca26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7074772119522095,\n",
       "  'token': 2018,\n",
       "  'token_str': 'had',\n",
       "  'sequence': 'i had seen him since the wedding'},\n",
       " {'score': 0.2832067310810089,\n",
       "  'token': 2031,\n",
       "  'token_str': 'have',\n",
       "  'sequence': 'i have seen him since the wedding'},\n",
       " {'score': 0.0019414956914260983,\n",
       "  'token': 2196,\n",
       "  'token_str': 'never',\n",
       "  'sequence': 'i never seen him since the wedding'},\n",
       " {'score': 0.0016844505444169044,\n",
       "  'token': 2310,\n",
       "  'token_str': 've',\n",
       "  'sequence': 'i ve seen him since the wedding'},\n",
       " {'score': 0.0014207483036443591,\n",
       "  'token': 2038,\n",
       "  'token_str': 'has',\n",
       "  'sequence': 'i has seen him since the wedding'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"I [MASK] seen him since the wedding\")\n",
    "#even outputs a hyphenated option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8806279f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.24308954179286957,\n",
       "  'token': 13877,\n",
       "  'token_str': 'waitress',\n",
       "  'sequence': \"my mother's friend's daughter worked as a waitress for a while\"},\n",
       " {'score': 0.13561439514160156,\n",
       "  'token': 10850,\n",
       "  'token_str': 'maid',\n",
       "  'sequence': \"my mother's friend's daughter worked as a maid for a while\"},\n",
       " {'score': 0.1341439038515091,\n",
       "  'token': 6821,\n",
       "  'token_str': 'nurse',\n",
       "  'sequence': \"my mother's friend's daughter worked as a nurse for a while\"},\n",
       " {'score': 0.061855580657720566,\n",
       "  'token': 19174,\n",
       "  'token_str': 'nanny',\n",
       "  'sequence': \"my mother's friend's daughter worked as a nanny for a while\"},\n",
       " {'score': 0.05383940041065216,\n",
       "  'token': 3836,\n",
       "  'token_str': 'teacher',\n",
       "  'sequence': \"my mother's friend's daughter worked as a teacher for a while\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"My mother's friend's daughter worked as a [MASK] for a while\")\n",
    "#Very stereotypical options but- I supposed it demonstrates an understanding of societal norms or more likely options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d7852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fntp",
   "language": "python",
   "name": "fntp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
