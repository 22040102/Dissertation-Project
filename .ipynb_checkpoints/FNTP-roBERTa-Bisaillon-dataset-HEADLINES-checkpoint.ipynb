{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4719d322",
   "metadata": {},
   "source": [
    "## RoBERTa Model\n",
    "\n",
    "##### roBERTa model implemented from huggingface transformers library.\n",
    "> https://huggingface.co/hamzab/roberta-fake-news-classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85626c6f",
   "metadata": {},
   "source": [
    "The model is a roberta-base fine-tuned on Bisaillon's fake-and-real-news-dataset. Initial Implemetation date: 13/07/2023.\n",
    "\n",
    "> https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset  \n",
    "\n",
    "It supposedly a 100% accuracy on that dataset. The model takes a news article and predicts if it is true or fake. This model can be used in real time by inputting a headline and copy of the news article (any given length). The model can directly be implemented from the huggingface text classification model library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b10c5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096ad6d",
   "metadata": {},
   "source": [
    "#### Initial test of the model\n",
    "I took a random news story from searching COVID-19 online and copied it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c79fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fake': 5.5498923757113516e-05, 'Real': 0.9999444484710693}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoco\\AppData\\Local\\Temp\\ipykernel_24912\\2965564230.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_fake(title,text):\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "    \n",
    "print(predict_fake(\"Covid tests for China travellers to England ending\",\"Travellers flying into England from mainland China will no longer have to provide proof of a negative pre-departure test from next month. The change will come into effect on 5 April - exactly three months after the measures started. Ministers brought in controls after a spike in cases following Beijing's relaxation of its zero-Covid policy. Their removal comes after greater transparency from China, the government said.In a statement, the Department of Health and Social Care (DHSC) said that there has been increased information on testing, vaccination and genomic sequencing results on China's domestic disease levels.The data indicates that Covid variants seen in China continue to be the same as those already circulating in the UK, it added.The Chinese Centre for Disease Control and Prevention also reported that all regions had passed their infection peak, the statement reported.The DHSC also announced that the UK Health Security Agency's (UKHSA) voluntary on-arrival testing programme of travellers from China to Heathrow airport has come to an end.\"))\n",
    "\n",
    "# https://www.bbc.co.uk/news/business-64993197 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c8c68",
   "metadata": {},
   "source": [
    "##### I took an article directly from the internet as quoted above from the website, we can see that the model shows  0.9999444484710693 'Real' value. \n",
    "\n",
    "## Project research\n",
    "For my project research, if humans are better than AI at detecting real or fake news. I will used sets of headlines that were created by LLMs. The ones chosen are guarunteed to be fake. The model is pre-trained to tale title and test however I will continue to only work with titles for the purpose of my project. Implemeted 17/08/2023.\n",
    "\n",
    "The outputs used are:\n",
    "(1) ChatGPT3.5 Output 9\n",
    "(2) BARD Outputs 8.1 & 9 (20 total)\n",
    "(3) HuggingChat Output 4\n",
    "Please refer to Output notebooks as necessary.\n",
    "\n",
    "The outputs used are ones which I believe are evidently fake or alternatively, where the AI has stated in the output that the headlines are false, just examples, or non genuine. So, I am looking for the model to output high scoring 'Fake' for all of these if the LLMs are assumed to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907e306",
   "metadata": {},
   "source": [
    "### (1) ChatGPT3.5 Output 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcffdf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoco\\AppData\\Local\\Temp\\ipykernel_24912\\1414402708.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fake': 0.9999790191650391, 'Real': 2.09736535907723e-05}\n",
      "{'Fake': 0.999980092048645, 'Real': 1.9965144019806758e-05}\n",
      "{'Fake': 0.99997878074646, 'Real': 2.122170917573385e-05}\n",
      "{'Fake': 0.9999792575836182, 'Real': 2.0707988369395025e-05}\n",
      "{'Fake': 0.9999791383743286, 'Real': 2.082955870719161e-05}\n",
      "{'Fake': 0.9999786615371704, 'Real': 2.1290852600941435e-05}\n",
      "{'Fake': 0.9999785423278809, 'Real': 2.1485398974618874e-05}\n",
      "{'Fake': 0.9999792575836182, 'Real': 2.073943142022472e-05}\n",
      "{'Fake': 0.9999791383743286, 'Real': 2.0917725123581477e-05}\n",
      "{'Fake': 0.9999799728393555, 'Real': 2.006770773732569e-05}\n",
      "{'Fake': 0.9999790191650391, 'Real': 2.1001875211368315e-05}\n",
      "{'Fake': 0.9999783039093018, 'Real': 2.1651387214660645e-05}\n",
      "{'Fake': 0.999980092048645, 'Real': 1.993968544411473e-05}\n",
      "{'Fake': 0.9999796152114868, 'Real': 2.0342647985671647e-05}\n",
      "{'Fake': 0.999980092048645, 'Real': 1.9918892576242797e-05}\n",
      "{'Fake': 0.9999798536300659, 'Real': 2.0198671336402185e-05}\n",
      "{'Fake': 0.9999796152114868, 'Real': 2.042179949057754e-05}\n",
      "{'Fake': 0.9999799728393555, 'Real': 2.0050165403517894e-05}\n",
      "{'Fake': 0.999980092048645, 'Real': 1.9954979507019743e-05}\n",
      "{'Fake': 0.9999788999557495, 'Real': 2.106779174937401e-05}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_fake(title,text):\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "    \n",
    "#print(predict_fake(\"\",\"\"))\n",
    "print(predict_fake(\"Government Unveils Ambitious Plan to Modernize Public Transport Infrastructure\",\"\"))     #1\n",
    "print(predict_fake(\"Landmark Education Reform Bill Passes Amidst Debate Over Curriculum Changes\",\"\"))        #2\n",
    "print(predict_fake(\"National Health Service Announces Innovative Telemedicine Initiative\",\"\"))               #3\n",
    "print(predict_fake(\"Local Community Rallies Together to Restore Historic Landmark\",\"\"))                      #4\n",
    "print(predict_fake(\"Exclusive Interview: Leading Scientist Discusses Breakthrough in Climate Research\",\"\"))  #5\n",
    "print(predict_fake(\"UK Economy Shows Signs of Recovery as Unemployment Rates Drop\",\"\"))                      #6\n",
    "print(predict_fake(\"New Study Reveals Alarming Rise in Childhood Obesity Rates\",\"\"))                         #7\n",
    "print(predict_fake(\"Royal Family Attends Charity Event, Highlights Philanthropic Efforts\",\"\"))               #8\n",
    "print(predict_fake(\"Brexit Trade Talks Reach Critical Phase as Negotiators Seek Common Ground\",\"\"))          #9\n",
    "print(predict_fake(\"Artificial Intelligence Adoption Grows, Raising Questions About Automation Impact\",\"\"))  #10\n",
    "print(predict_fake(\"Nation Celebrates Cultural Diversity with Vibrant Annual Festival\",\"\"))                  #11\n",
    "print(predict_fake(\"National Security Alert: Government Increases Counterterrorism Measures\",\"\"))            #12\n",
    "print(predict_fake(\"Investigation Uncovers Scandal Involving Prominent Political Figure\",\"\"))                #13\n",
    "print(predict_fake(\"Wildlife Conservation Efforts Pay Off as Endangered Species Thrive\",\"\"))                 #14\n",
    "print(predict_fake(\"Youth-Led Climate Protest Draws Thousands, Demanding Government Action\",\"\"))             #15\n",
    "print(predict_fake(\"Tech Startups Flourish as Entrepreneurial Spirit Gains Momentum\",\"\"))                    #16\n",
    "print(predict_fake(\"Housing Crisis Prompts Calls for Affordable Housing Solutions\",\"\"))                      #17\n",
    "print(predict_fake(\"Transportation Disruption: Commuters Brace for Rail Network Overhaul\",\"\"))               #18\n",
    "print(predict_fake(\"Entertainment Industry Embraces Virtual Platforms Amidst Pandemic Challenges\",\"\"))       #19\n",
    "print(predict_fake(\"Innovative British Invention Revolutionizes Renewable Energy Storage\",\"\"))               #20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcc3e6",
   "metadata": {},
   "source": [
    "#### All scores above are 0.9999 or higher for 'Fake'. This group I was certain that they were fake due to the lake of specifics on people and places.\n",
    "# ______________________________________\n",
    "\n",
    "### (2) BARD Outputs 8.1 & 9 (20 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da998773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoco\\AppData\\Local\\Temp\\ipykernel_24912\\1637073960.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fake': 0.00045229707029648125, 'Real': 0.9995476603507996}\n",
      "{'Fake': 0.0002969525521621108, 'Real': 0.9997029900550842}\n",
      "{'Fake': 0.9522378444671631, 'Real': 0.047762103378772736}\n",
      "{'Fake': 0.0006945973145775497, 'Real': 0.9993053674697876}\n",
      "{'Fake': 0.00012889583013020456, 'Real': 0.9998711347579956}\n",
      "{'Fake': 0.00011262487532803789, 'Real': 0.9998873472213745}\n",
      "{'Fake': 0.0002191067032981664, 'Real': 0.9997809529304504}\n",
      "{'Fake': 0.957062304019928, 'Real': 0.04293769598007202}\n",
      "{'Fake': 0.04002648591995239, 'Real': 0.9599735736846924}\n",
      "{'Fake': 0.9988986253738403, 'Real': 0.0011013949988409877}\n",
      "{'Fake': 0.00024746471899561584, 'Real': 0.9997525811195374}\n",
      "{'Fake': 0.9995028972625732, 'Real': 0.0004971075686626136}\n",
      "{'Fake': 0.00011431254824856296, 'Real': 0.9998856782913208}\n",
      "{'Fake': 0.0013205165741965175, 'Real': 0.9986794590950012}\n",
      "{'Fake': 0.0002755498280748725, 'Real': 0.9997244477272034}\n",
      "{'Fake': 0.999737560749054, 'Real': 0.00026239134604111314}\n",
      "{'Fake': 0.9370129108428955, 'Real': 0.06298712641000748}\n",
      "{'Fake': 0.8966890573501587, 'Real': 0.10331086069345474}\n",
      "{'Fake': 0.0004110271984245628, 'Real': 0.9995890259742737}\n",
      "{'Fake': 0.07960975170135498, 'Real': 0.920390248298645}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_fake(title,text):\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "    \n",
    "#print(predict_fake(\"\",\"\"))\n",
    "print(predict_fake(\"Queen Elizabeth II to step down from throne after 70 years\",\"\"))                    #1\n",
    "print(predict_fake(\"UK government to introduce mandatory vaccination for all adults\",\"\"))               #2\n",
    "print(predict_fake(\"New study finds that climate change is causing more extreme weather events\",\"\"))    #3\n",
    "print(predict_fake(\"Trump announces run for president in 2024\",\"\"))                                     #4\n",
    "print(predict_fake(\"North Korea fires ballistic missile into the Sea of Japan\",\"\"))                     #5\n",
    "print(predict_fake(\"China overtakes US as world's largest economy\",\"\"))                                 #6\n",
    "print(predict_fake(\"EU agrees to ban all Russian oil imports\",\"\"))                                      #7\n",
    "print(predict_fake(\"Huge asteroid to pass close to Earth next week\",\"\"))                                #8\n",
    "print(predict_fake(\"Scientists discover new planet that could support life\",\"\"))                        #9\n",
    "print(predict_fake(\"Major breakthrough in cancer research\",\"\"))                                         #10\n",
    "print(predict_fake(\"Boris Johnson to resign after partygate scandal\",\"\"))                               #11\n",
    "print(predict_fake(\"Keir Starmer to become next Prime Minister\",\"\"))                                    #12\n",
    "print(predict_fake(\"Labour Party to win general election with landslide victory\",\"\"))                   #13\n",
    "print(predict_fake(\"SNP to win Scottish independence referendum\",\"\"))                                   #14\n",
    "print(predict_fake(\"UK to leave European Union without a deal\",\"\"))                                     #15\n",
    "print(predict_fake(\"Second COVID-19 pandemic hits UK\",\"\"))                                              #16\n",
    "print(predict_fake(\"Huge earthquake hits London\",\"\"))                                                   #17\n",
    "print(predict_fake(\"Met Office issues 'red alert' for extreme heat\",\"\"))                                #18\n",
    "print(predict_fake(\"UK to experience worst drought in 100 years\",\"\"))                                   #19\n",
    "print(predict_fake(\"Wildfires destroy large swathes of countryside\",\"\"))                                #20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c71cf9",
   "metadata": {},
   "source": [
    "##### Accordinging to this roBERTa model, BARD gave me true and fake content. The output from these included BARD stating 'These headlines are all plausible and could be easily mistaken for real news if they were published by a UK news agency. However, they are all false.' We cannot trust generative language models either without legitimate sources. \n",
    "\n",
    "##### This highlights the problem of where and who we believe. I have more trust in this roBERTa model than the generative AI as some of which state they can output things that are factually incorrect.\n",
    "# ______________________________________\n",
    "\n",
    "\n",
    "\n",
    "### (3) HuggingChat Output 4\n",
    "\"Hong Kong police arrest dozens in latest anti-government protests\"\n",
    "\"Mali's Keita names new government after resignation of prime minister\"\n",
    "\"UN Security Council extends Somalia peacekeeping mission\"\n",
    "\"Czech PM Babis survives no-confidence vote, keeps grip on power\"\n",
    "\"Myanmar's Suu Kyi faces pressure over Rohingya genocide allegations at ICJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e3d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoco\\AppData\\Local\\Temp\\ipykernel_24912\\2098638969.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fake': 7.238820398924872e-05, 'Real': 0.9999276399612427}\n",
      "{'Fake': 0.00011133169027743861, 'Real': 0.9998886585235596}\n",
      "{'Fake': 3.419608037802391e-05, 'Real': 0.9999657869338989}\n",
      "{'Fake': 3.326481964904815e-05, 'Real': 0.9999667406082153}\n",
      "{'Fake': 6.742769619449973e-05, 'Real': 0.9999325275421143}\n",
      "{'Fake': 8.306757808895782e-05, 'Real': 0.9999169111251831}\n",
      "{'Fake': 3.4630684240255505e-05, 'Real': 0.9999653100967407}\n",
      "{'Fake': 0.00013278414553496987, 'Real': 0.9998672008514404}\n",
      "{'Fake': 0.22115154564380646, 'Real': 0.77884840965271}\n",
      "{'Fake': 6.767686136299744e-05, 'Real': 0.9999322891235352}\n",
      "{'Fake': 8.927072485676035e-05, 'Real': 0.9999107122421265}\n",
      "{'Fake': 3.624751843744889e-05, 'Real': 0.9999637603759766}\n",
      "{'Fake': 6.514920096378773e-05, 'Real': 0.9999347925186157}\n",
      "{'Fake': 5.127354233991355e-05, 'Real': 0.9999487400054932}\n",
      "{'Fake': 3.325790385133587e-05, 'Real': 0.9999667406082153}\n",
      "{'Fake': 0.00018118921434506774, 'Real': 0.9998188614845276}\n",
      "{'Fake': 3.879232463077642e-05, 'Real': 0.999961256980896}\n",
      "{'Fake': 0.09032368659973145, 'Real': 0.9096762537956238}\n",
      "{'Fake': 0.0001405631919624284, 'Real': 0.9998594522476196}\n",
      "{'Fake': 5.0533562898635864e-05, 'Real': 0.9999494552612305}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def predict_fake(title,text):\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "    \n",
    "#print(predict_fake(\"\",\"\"))\n",
    "print(predict_fake(\"US and China edge closer to trade deal, but tensions remain\",\"\"))                            #1\n",
    "print(predict_fake(\"NATO chief warns of Russian threat to European security\",\"\"))                                #2\n",
    "print(predict_fake(\"Iran nuclear deal on life support as France, Germany threaten to pull out\",\"\"))              #3\n",
    "print(predict_fake(\"North Korea fires ballistic missile, sparking alarm in Seoul and Tokyo\",\"\"))                 #4\n",
    "print(predict_fake(\"UK PM Johnson denies cover-up over Parliament shutdown, defends Brexit strategy\",\"\"))        #5\n",
    "print(predict_fake(\"Pakistan PM Khan calls for dialogue with India after Kashmir clashes\",\"\"))                   #6\n",
    "print(predict_fake(\"Putin's party wins majority in Russian parliamentary elections\",\"\"))                         #7\n",
    "print(predict_fake(\"US Defense Secretary Esper visits Kabul, promises continued support for Afghan forces\",\"\"))  #8\n",
    "print(predict_fake(\"Sudan's Bashir sentenced to 20 years in prison for corruption\",\"\"))                          #9\n",
    "print(predict_fake(\"Protests erupt in Egypt after government proposes constitutional changes\",\"\"))               #10\n",
    "print(predict_fake(\"Netanyahu's Likud Party wins Israeli election, setting up right-wing coalition\",\"\"))         #11\n",
    "print(predict_fake(\"Thousands march in London to demand second Brexit referendum\",\"\"))                           #12\n",
    "print(predict_fake(\"US and South Korea begin joint military exercises, angering Pyongyang\",\"\"))                  #13\n",
    "print(predict_fake(\"Erdogan's AKP loses Istanbul mayoralty in blow to Turkish president\",\"\"))                    #14\n",
    "print(predict_fake(\"Hong Kong police arrest dozens in latest anti-government protests\",\"\"))                      #15\n",
    "print(predict_fake(\"Indonesia's Widodo inaugurated for second term, vows to tackle radicalism\",\"\"))              #16\n",
    "print(predict_fake(\"Mali's Keita names new government after resignation of prime minister\",\"\"))                  #17\n",
    "print(predict_fake(\"UN Security Council extends Somalia peacekeeping mission\",\"\"))                               #18\n",
    "print(predict_fake(\"Czech PM Babis survives no-confidence vote, keeps grip on power\",\"\"))                        #19\n",
    "print(predict_fake(\"Myanmar's Suu Kyi faces pressure over Rohingya genocide allegations at ICJ\",\"\"))             #20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d645e",
   "metadata": {},
   "source": [
    "#### This output on HugginChat also stated to me 'Please note that these are just examples and not real news headlines.' at the end of the output post the headlines. \n",
    "\n",
    "I researched the anomaly, headline 'Sudan's Bashir sentenced to 20 years in prison for corruption', the statement overall is false, the number of years is incorrect (2 years not 20 years). Which explains why the model has a lower 'Real' accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9286d",
   "metadata": {},
   "source": [
    "#### I will continue this research futher by running the outputs through an open-sourced BERT model via huggingface Transformers. This is bert-base-uncased run on colab. I can only assume what the roBERTa model has predicted is true based on the supposedly '100%' accuracy. I will use this as validation for the base-uncased model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65f632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fntp",
   "language": "python",
   "name": "fntp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
